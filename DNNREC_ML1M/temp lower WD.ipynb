{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/kirana/Documents/phd/experiment1_new/DNNREC_ML1M'\n",
    "DATAPATH='/home/kirana/Documents/final_dissertation_final/experiments/datasets/ml-1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import pickle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dftrain,dfvalid,results_concat]=pickle.load(open(f'{DATAPATH}/df_side_cold_runother.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([dftrain,dfvalid[dftrain.columns]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_idx={j:i+1 for i, j in enumerate(df['userId'].unique())}\n",
    "item_to_idx={j:i+1 for i,j in enumerate(df['itemId'].unique())}\n",
    "idx_to_user={i+1:j for i, j in enumerate(df['userId'].unique())}\n",
    "idx_to_item={i+1:j for i,j in enumerate(df['itemId'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain['user_idx']=[user_to_idx[i] for i in dftrain['userId']]\n",
    "dftrain['item_idx']=[item_to_idx[i] for i in dftrain['itemId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvalid['user_idx']=[user_to_idx[i] for i in dfvalid['userId']]\n",
    "dfvalid['item_idx']=[item_to_idx[i] for i in dfvalid['itemId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([df, dftrain,dfvalid,idx_to_user,idx_to_item,item_to_idx,user_to_idx],open(f'{DATAPATH}/reads.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfdata (torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self,dfX,dfY):\n",
    "        self.dfX,self.dfY=dfX,dfY\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.dfX.shape[0]\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return torch.LongTensor(self.dfX.iloc[idx].values),torch.FloatTensor([self.dfY.values[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=cfdata(dftrain[['user_idx','item_idx']],dftrain['rating'])\n",
    "dsvalid=cfdata(dfvalid[['user_idx','item_idx']],dfvalid['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(895738, 392)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain=DataLoader(dstrain,bs,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlvalid=DataLoader(dsvalid,bs,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_to_idx),len(item_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users=len(user_to_idx)\n",
    "n_items=len(item_to_idx)\n",
    "n_emb_user=25\n",
    "n_emb_item=25\n",
    "min_rating=min(dftrain['rating'])\n",
    "max_rating=max(dftrain['rating'])\n",
    "dropout_e=0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cf(nn.Module):    \n",
    "    def __init__(self,n_users,n_emb_user,n_emb_item,n_items,min_rating,max_rating,dropout_e=0.01):\n",
    "        super().__init__()\n",
    "        self.n_users,self.n_emb_user,self.n_emb_item,self.n_items,self.min_rating,self.max_rating=\\\n",
    "                    n_users,n_emb_user,n_emb_item,n_items,min_rating,max_rating\n",
    "        self.dropout_e=dropout_e\n",
    "        self.create_architecture()\n",
    "        self.init_parameters()\n",
    "        self.criterion=nn.MSELoss()\n",
    "        \n",
    "        \n",
    "    def create_architecture(self):\n",
    "        self.emb_user=nn.Embedding(self.n_users+1,self.n_emb_user)\n",
    "        self.emb_item=nn.Embedding(self.n_items+1,self.n_emb_item)\n",
    "        self.emb_dropout=nn.Dropout(self.dropout_e)\n",
    "        self.ub=nn.Embedding(self.n_users+1,1)\n",
    "        self.ib=nn.Embedding(self.n_items+1,1)\n",
    "\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def init_parameters(self):\n",
    "        nn.init.kaiming_normal_(self.emb_user.weight.data)\n",
    "        nn.init.kaiming_normal_(self.emb_item.weight.data)\n",
    "        nn.init.kaiming_normal_(self.ub.weight.data)\n",
    "        nn.init.kaiming_normal_(self.ib.weight.data)\n",
    "\n",
    "       \n",
    "    def forward (self,Xb,Yb):               \n",
    "        users=self.emb_dropout(self.emb_user(Xb[:,0]))\n",
    "        items=self.emb_dropout(self.emb_item(Xb[:,1]))\n",
    "        users_bias=self.emb_dropout(self.ub(Xb[:,0]))\n",
    "        items_bias=self.emb_dropout(self.ib(Xb[:,1]))\n",
    "\n",
    "        out=(users*items).sum(1)+users_bias.squeeze()+items_bias.squeeze()\n",
    "        out=self.sigmoid(out)\n",
    "        preds=out*(self.max_rating-self.min_rating)+self.min_rating\n",
    "        preds=preds.view(-1,1)\n",
    "        loss=self.criterion(preds,Yb)\n",
    "        return preds,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfobj=cf(n_users,n_emb_user,n_emb_item,n_items,min_rating,max_rating,dropout_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cf(\n",
       "  (emb_user): Embedding(6041, 25)\n",
       "  (emb_item): Embedding(3707, 25)\n",
       "  (emb_dropout): Dropout(p=0.05)\n",
       "  (ub): Embedding(6041, 1)\n",
       "  (ib): Embedding(3707, 1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Xb, Yb in dltrain:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.8665],\n",
       "         [4.7776],\n",
       "         [1.2330],\n",
       "         [4.9396],\n",
       "         [3.9664],\n",
       "         [3.2082],\n",
       "         [2.3126],\n",
       "         [4.7531],\n",
       "         [1.8818],\n",
       "         [4.8793],\n",
       "         [4.3598],\n",
       "         [4.9370],\n",
       "         [2.8825],\n",
       "         [3.9926],\n",
       "         [2.3257],\n",
       "         [2.8757],\n",
       "         [1.2889],\n",
       "         [1.1052],\n",
       "         [4.6572],\n",
       "         [4.2677],\n",
       "         [1.4131],\n",
       "         [4.3294],\n",
       "         [1.8394],\n",
       "         [3.3024],\n",
       "         [3.6478],\n",
       "         [2.0745],\n",
       "         [1.8344],\n",
       "         [1.1325],\n",
       "         [2.1193],\n",
       "         [4.8376],\n",
       "         [1.0647],\n",
       "         [2.2648],\n",
       "         [4.9432],\n",
       "         [1.2542],\n",
       "         [4.2381],\n",
       "         [4.4885],\n",
       "         [3.1310],\n",
       "         [4.5297],\n",
       "         [4.1998],\n",
       "         [3.1343],\n",
       "         [3.7366],\n",
       "         [1.2614],\n",
       "         [2.0287],\n",
       "         [1.9717],\n",
       "         [1.2695],\n",
       "         [2.7906],\n",
       "         [1.1370],\n",
       "         [1.6234],\n",
       "         [4.8605],\n",
       "         [2.8116],\n",
       "         [3.9422],\n",
       "         [3.9050],\n",
       "         [4.1872],\n",
       "         [1.8036],\n",
       "         [2.2935],\n",
       "         [4.4980],\n",
       "         [2.1340],\n",
       "         [1.9931],\n",
       "         [1.0738],\n",
       "         [1.3862],\n",
       "         [2.3502],\n",
       "         [2.6760],\n",
       "         [2.4478],\n",
       "         [2.1100]], grad_fn=<ViewBackward>),\n",
       " tensor(3.6146, grad_fn=<MseLossBackward>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfobj.forward(Xb,Yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=1.1,start_lr=2e-2, end_lr=5e-4,error_type=\"mse\",\n",
    "                cycle_const=False):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_const=cycle_const\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.end_lr=end_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        self.ratio=self.end_lr/self.start_lr\n",
    "        self.num_steps=self.cycle_mult\n",
    "        self.reset_cycle=self.cycle_mult\n",
    "        self.error_type=error_type\n",
    "        self.scores=[]\n",
    "        self.generate_scores=False\n",
    "        \n",
    "    def fit (self,Xb,Yb,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        preds,loss=self.model(Xb,Yb)\n",
    "\n",
    "     \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=loss.item()\n",
    "    \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.error_type == \"mse\":\n",
    "                acc=nn.L1Loss() (preds,Yb)\n",
    "                myrmse=np.sqrt(myloss)\n",
    "            else:\n",
    "                acc=nn.MSELoss() (preds,Yb)\n",
    "                myrmse=np.sqrt(acc.item())\n",
    "            acc=acc.item()\n",
    "                 \n",
    "        if mode_train==False:\n",
    "            if self.generate_scores:\n",
    "                self.scores.append(preds.detach().cpu().numpy().flatten())\n",
    "        del preds\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc, myrmse\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        epoch_rmse=0\n",
    "\n",
    "        for Xb,Yb in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Yb=Yb.to(self.device)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "            loss,acc,myrmse=self.fit(Xb,Yb,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "\n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            epoch_rmse+=myrmse\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  ')  \n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "        epoch_rmse=epoch_rmse/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc,epoch_rmse\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1,ylim=None,xlim=None):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):              \n",
    "        for epoch in range(n_epochs):                \n",
    "            loss,acc,rmse=self.run_epoch(dltrain,True)\n",
    "\n",
    "            lossv,accv,rmsev=self.run_epoch(dlvalid,mode_train=False)\n",
    "           \n",
    "            if self.error_type==\"mse\":\n",
    "                loss_mse=loss\n",
    "                loss_rmse=rmse\n",
    "                loss_mae=acc\n",
    "                lossv_mse=lossv\n",
    "                lossv_rmse=rmsev\n",
    "                lossv_mae=accv\n",
    "                \n",
    "            else:\n",
    "                loss_mse=acc\n",
    "                loss_rmse=rmse\n",
    "                loss_mae=loss\n",
    "                lossv_mse=accv\n",
    "                lossv_rmse=rmsev\n",
    "                lossv_mae=lossv\n",
    "            \n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss} \\\n",
    "                Valid Loss:{lossv} Train RMSE:{loss_rmse} Valid RMSE:{lossv_rmse} Train MSE:{loss_mse} Valid MSE:{lossv_mse} \\\n",
    "                Train MAE:{loss_mae} Valid MAE:{lossv_mae}')\n",
    "\n",
    "              \n",
    "         \n",
    "     \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==self.reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    self.wd=self.start_wd\n",
    "                    if self.cycle_const == False:\n",
    "                        self.reset_cycle*=self.cycle_mult\n",
    "                    #reset_cycle=self.n_epoch+reset_cycle\n",
    "                    self.n_epoch=0\n",
    "                    self.ratio=self.end_lr/self.start_lr\n",
    "                    self.num_steps=self.reset_cycle\n",
    "                else:\n",
    "                    #self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    #if self.n_epoch>1:\n",
    "                    self.wd*=self.wd_mult\n",
    "                    self.lr=self.lr*(self.end_lr/self.start_lr)**(1/self.num_steps)\n",
    "                    self.n_epoch+=1\n",
    "        \n",
    "\n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                param_group['weight_decay']=self.wd\n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    del cfobj\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfobj=cf(n_users,n_emb_user,n_emb_item,n_items,min_rating,max_rating,dropout_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfobj=cfobj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cf(\n",
       "  (emb_user): Embedding(6041, 25)\n",
       "  (emb_item): Embedding(3707, 25)\n",
       "  (emb_dropout): Dropout(p=0.05)\n",
       "  (ub): Embedding(6041, 1)\n",
       "  (ib): Embedding(3707, 1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13996"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=0\n",
    "optimizer=torch.optim.Adam(cfobj.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(cfobj,optimizer,None,device,0,5000,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:5000 3.1021770522117613  \n",
      "Batch:10000 2.5510578604280947  \n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(1e-4,1e-1,dltrain,len(dltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cfobj\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfobj=cf(n_users,n_emb_user,n_emb_item,n_items,min_rating,max_rating,dropout_e)\n",
    "cfobj=cfobj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cf(\n",
       "  (emb_user): Embedding(6041, 25)\n",
       "  (emb_item): Embedding(3707, 25)\n",
       "  (emb_dropout): Dropout(p=0.05)\n",
       "  (ub): Embedding(6041, 1)\n",
       "  (ib): Embedding(3707, 1)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(cfobj.parameters(),lr=1e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(cfobj,optimizer,None,device,0,16000,0.25,cycle_mult=2,start_lr=1e-2,end_lr=5e-3,wd_mult=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.01 Weight Decay 1e-06 Train Loss:1.2342072905843242                 Valid Loss:1.1678680041160454 Train RMSE:1.1005589032930216 Valid RMSE:1.0647046714990769 Train MSE:1.2342072905843242 Valid MSE:1.1678680041160454                 Train MAE:0.8640098184236427 Valid MAE:0.8409687129179539\n",
      "Epoch:1 Learning rate 0.007071067811865476 Weight Decay 1.2e-06 Train Loss:0.9642379445096498                 Valid Loss:1.0100798330931888 Train RMSE:0.9768973213174288 Valid RMSE:0.9903872785336377 Train MSE:0.9642379445096498 Valid MSE:1.0100798330931888                 Train MAE:0.7635061983407719 Valid MAE:0.7839064560488405\n",
      "Epoch:2 Learning rate 0.005000000000000001 Weight Decay 1.44e-06 Train Loss:0.8313389509515988                 Valid Loss:0.920276282776081 Train RMSE:0.9070110506447105 Valid RMSE:0.9442546129733151 Train MSE:0.8313389509515988 Valid MSE:0.920276282776081                 Train MAE:0.711442543435911 Valid MAE:0.7506361411746411\n",
      "Epoch:3 Learning rate 0.01 Weight Decay 1e-06 Train Loss:1.0633359384872327                 Valid Loss:1.1819187882336384 Train RMSE:1.0249247238135264 Valid RMSE:1.0716093461867044 Train MSE:1.0633359384872327 Valid MSE:1.1819187882336384                 Train MAE:0.7976045360579495 Valid MAE:0.8433960110806864\n",
      "Epoch:4 Learning rate 0.008408964152537146 Weight Decay 1.2e-06 Train Loss:1.0102259663811204                 Valid Loss:1.0760935584570248 Train RMSE:0.9999265200836938 Valid RMSE:1.0225673766319772 Train MSE:1.0102259663811204 Valid MSE:1.0760935584570248                 Train MAE:0.7784851256967715 Valid MAE:0.8075922094673301\n",
      "Epoch:5 Learning rate 0.007071067811865475 Weight Decay 1.44e-06 Train Loss:0.9207967565541064                 Valid Loss:1.0066127369576119 Train RMSE:0.9546791645034717 Valid RMSE:0.9884481716880644 Train MSE:0.9207967565541064 Valid MSE:1.0066127369576119                 Train MAE:0.7458142034728618 Valid MAE:0.7828246906573102\n",
      "Epoch:6 Learning rate 0.005946035575013605 Weight Decay 1.7279999999999998e-06 Train Loss:0.8507667652672787                 Valid Loss:0.947140557081219 Train RMSE:0.9176034167546646 Valid RMSE:0.9584184385801197 Train MSE:0.8507667652672787 Valid MSE:0.947140557081219                 Train MAE:0.7188244379075229 Valid MAE:0.760126371381477\n",
      "Epoch:7 Learning rate 0.004999999999999999 Weight Decay 2.0735999999999995e-06 Train Loss:0.793559738029477                 Valid Loss:0.9132155241297566 Train RMSE:0.8861961494103855 Valid RMSE:0.9406397225199233 Train MSE:0.793559738029477 Valid MSE:0.9132155241297566                 Train MAE:0.6956696835678964 Valid MAE:0.7473603312909347\n",
      "Epoch:8 Learning rate 0.01 Weight Decay 1e-06 Train Loss:1.0563168535874072                 Valid Loss:1.169114289477933 Train RMSE:1.021454229663325 Valid RMSE:1.065911998177061 Train MSE:1.0563168535874072 Valid MSE:1.169114289477933                 Train MAE:0.7947973129505871 Valid MAE:0.8384944449628852\n",
      "Epoch:9 Learning rate 0.009170040432046712 Weight Decay 1.2e-06 Train Loss:1.046467817097553                 Valid Loss:1.1146824252218537 Train RMSE:1.0177492867386633 Valid RMSE:1.0410436680955228 Train MSE:1.046467817097553 Valid MSE:1.1146824252218537                 Train MAE:0.7913335692579319 Valid MAE:0.8200943525846356\n",
      "Epoch:10 Learning rate 0.008408964152537144 Weight Decay 1.44e-06 Train Loss:0.9929563770122308                 Valid Loss:1.0618149840751456 Train RMSE:0.9912807809883392 Valid RMSE:1.0155464841786457 Train MSE:0.9929563770122308 Valid MSE:1.0618149840751456                 Train MAE:0.7723255441504125 Valid MAE:0.8022520998213383\n",
      "Epoch:11 Learning rate 0.007711054127039703 Weight Decay 1.7279999999999998e-06 Train Loss:0.9450275896574368                 Valid Loss:1.022601352492433 Train RMSE:0.9671391496674464 Valid RMSE:0.996398566703166 Train MSE:0.9450275896574368 Valid MSE:1.022601352492433                 Train MAE:0.755768633806116 Valid MAE:0.7896322728809373\n",
      "Epoch:12 Learning rate 0.007071067811865474 Weight Decay 2.0735999999999995e-06 Train Loss:0.9028965717244911                 Valid Loss:0.9846386955657476 Train RMSE:0.9452951815324486 Valid RMSE:0.9771885622877103 Train MSE:0.9028965717244911 Valid MSE:0.9846386955657476                 Train MAE:0.7400306414245332 Valid MAE:0.7746238452630472\n",
      "Epoch:13 Learning rate 0.0064841977732550465 Weight Decay 2.4883199999999992e-06 Train Loss:0.8656845568788668                 Valid Loss:0.9570784876847369 Train RMSE:0.9255568075261756 Valid RMSE:0.9632572792925406 Train MSE:0.8656845568788668 Valid MSE:0.9570784876847369                 Train MAE:0.7256691383464604 Valid MAE:0.7654325703646022\n",
      "Epoch:14 Learning rate 0.005946035575013603 Weight Decay 2.985983999999999e-06 Train Loss:0.8356194426908463                 Valid Loss:0.9283883372334272 Train RMSE:0.9094007450445444 Valid RMSE:0.9488187032756006 Train MSE:0.8356194426908463 Valid MSE:0.9283883372334272                 Train MAE:0.7140737988734014 Valid MAE:0.7550645058168199\n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.start_lr=7e-3\n",
    "learner.lr=7e-3\n",
    "for param in optimizer.param_groups:\n",
    "    param['lr']=7e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.02 Weight Decay 5e-06 Train Loss:1.9025736793973644                 Valid Loss:2.064982513160846 Train RMSE:1.370992410458385 Valid RMSE:1.4203820747355163 Train MSE:1.9025736793973644 Valid MSE:2.064982513160846                 Train MAE:1.0623491609495141 Valid MAE:1.1205066185894001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-81efa181904b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-baaee2378bc0>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(self, dltrain, dlvalid, n_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmsev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-baaee2378bc0>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, iterator, mode_train, lrs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmyrmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-baaee2378bc0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, Xb, Yb, mode_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mmyrmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>Cold Start Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.762661</td>\n",
       "      <td>0.873305</td>\n",
       "      <td>0.686658</td>\n",
       "      <td>0.419384</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.975590</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>0.787813</td>\n",
       "      <td>0.184044</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>1.004593</td>\n",
       "      <td>1.002294</td>\n",
       "      <td>0.866920</td>\n",
       "      <td>-0.205512</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.762661</td>\n",
       "      <td>0.873305</td>\n",
       "      <td>0.686658</td>\n",
       "      <td>0.419384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.975705</td>\n",
       "      <td>0.987778</td>\n",
       "      <td>0.788064</td>\n",
       "      <td>0.184027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.781557</td>\n",
       "      <td>0.884057</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.402036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.760565</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.681210</td>\n",
       "      <td>0.420979</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.965663</td>\n",
       "      <td>0.982682</td>\n",
       "      <td>0.789363</td>\n",
       "      <td>0.192346</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>1.005146</td>\n",
       "      <td>1.002569</td>\n",
       "      <td>0.877412</td>\n",
       "      <td>-0.206175</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.760565</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.681210</td>\n",
       "      <td>0.420979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.965808</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>0.789637</td>\n",
       "      <td>0.192304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.778769</td>\n",
       "      <td>0.882479</td>\n",
       "      <td>0.690827</td>\n",
       "      <td>0.404169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.876115</td>\n",
       "      <td>0.686994</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>1.197711</td>\n",
       "      <td>1.094400</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>1.190927</td>\n",
       "      <td>1.091296</td>\n",
       "      <td>0.965662</td>\n",
       "      <td>-0.429112</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svd</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.876115</td>\n",
       "      <td>0.686994</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>1.197686</td>\n",
       "      <td>1.094388</td>\n",
       "      <td>0.917534</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.805726</td>\n",
       "      <td>0.897623</td>\n",
       "      <td>0.707442</td>\n",
       "      <td>0.383544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.916385</td>\n",
       "      <td>0.718073</td>\n",
       "      <td>0.360686</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.968217</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.787066</td>\n",
       "      <td>0.190210</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.969763</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.839762</td>\n",
       "      <td>0.916385</td>\n",
       "      <td>0.718073</td>\n",
       "      <td>0.360686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.968187</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.190315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.922579</td>\n",
       "      <td>0.724209</td>\n",
       "      <td>0.348788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.908316</td>\n",
       "      <td>0.712054</td>\n",
       "      <td>0.371896</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.968217</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.787066</td>\n",
       "      <td>0.190210</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.969763</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.908316</td>\n",
       "      <td>0.712054</td>\n",
       "      <td>0.371896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.968187</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.190315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.837734</td>\n",
       "      <td>0.915278</td>\n",
       "      <td>0.718724</td>\n",
       "      <td>0.359055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.802753</td>\n",
       "      <td>0.895965</td>\n",
       "      <td>0.699557</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.968217</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.787066</td>\n",
       "      <td>0.190210</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.969763</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.802753</td>\n",
       "      <td>0.895965</td>\n",
       "      <td>0.699557</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      method       mse      rmse       mae  r2_score  \\\n",
       "0  biasedmatrixfactorization  0.762661  0.873305  0.686658  0.419384   \n",
       "1  biasedmatrixfactorization  0.975590  0.987719  0.787813  0.184044   \n",
       "2  biasedmatrixfactorization  1.004593  1.002294  0.866920 -0.205512   \n",
       "3  biasedmatrixfactorization  1.161611  1.077781  1.000000 -0.161611   \n",
       "0  biasedmatrixfactorization  0.762661  0.873305  0.686658  0.419384   \n",
       "1  biasedmatrixfactorization  0.975705  0.987778  0.788064  0.184027   \n",
       "0  biasedmatrixfactorization  0.781557  0.884057  0.695652  0.402036   \n",
       "0                svdplusplus  0.760565  0.872104  0.681210  0.420979   \n",
       "1                svdplusplus  0.965663  0.982682  0.789363  0.192346   \n",
       "2                svdplusplus  1.005146  1.002569  0.877412 -0.206175   \n",
       "3                svdplusplus  1.161611  1.077781  1.000000 -0.161611   \n",
       "0                svdplusplus  0.760565  0.872104  0.681210  0.420979   \n",
       "1                svdplusplus  0.965808  0.982755  0.789637  0.192304   \n",
       "0                svdplusplus  0.778769  0.882479  0.690827  0.404169   \n",
       "0                        svd  0.767578  0.876115  0.686994  0.415640   \n",
       "1                        svd  1.197711  1.094400  0.917391 -0.001733   \n",
       "2                        svd  1.190927  1.091296  0.965662 -0.429112   \n",
       "3                        svd  1.161611  1.077781  1.000000 -0.161611   \n",
       "0                        svd  0.767578  0.876115  0.686994  0.415640   \n",
       "1                        svd  1.197686  1.094388  0.917534 -0.001614   \n",
       "0                        svd  0.805726  0.897623  0.707442  0.383544   \n",
       "0              userknncosine  0.839762  0.916385  0.718073  0.360686   \n",
       "1              userknncosine  0.968217  0.983980  0.787066  0.190210   \n",
       "2              userknncosine  0.940441  0.969763  0.842502 -0.128529   \n",
       "3              userknncosine  1.161611  1.077781  1.000000 -0.161611   \n",
       "0              userknncosine  0.839762  0.916385  0.718073  0.360686   \n",
       "1              userknncosine  0.968187  0.983965  0.787255  0.190315   \n",
       "0              userknncosine  0.851153  0.922579  0.724209  0.348788   \n",
       "0             userknnpearson  0.825038  0.908316  0.712054  0.371896   \n",
       "1             userknnpearson  0.968217  0.983980  0.787066  0.190210   \n",
       "2             userknnpearson  0.940441  0.969763  0.842502 -0.128529   \n",
       "3             userknnpearson  1.161611  1.077781  1.000000 -0.161611   \n",
       "0             userknnpearson  0.825038  0.908316  0.712054  0.371896   \n",
       "1             userknnpearson  0.968187  0.983965  0.787255  0.190315   \n",
       "0             userknnpearson  0.837734  0.915278  0.718724  0.359055   \n",
       "0             itemknnpearson  0.802753  0.895965  0.699557  0.388861   \n",
       "1             itemknnpearson  0.968217  0.983980  0.787066  0.190210   \n",
       "2             itemknnpearson  0.940441  0.969763  0.842502 -0.128529   \n",
       "3             itemknnpearson  1.161611  1.077781  1.000000 -0.161611   \n",
       "0             itemknnpearson  0.802753  0.895965  0.699557  0.388861   \n",
       "\n",
       "       Cold Start Group  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_concat[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>Cold Start Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.968187</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.190315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknnpearson</td>\n",
       "      <td>0.817426</td>\n",
       "      <td>0.904116</td>\n",
       "      <td>0.707335</td>\n",
       "      <td>0.374592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.813202</td>\n",
       "      <td>0.901777</td>\n",
       "      <td>0.706219</td>\n",
       "      <td>0.380906</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.968217</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.787066</td>\n",
       "      <td>0.190210</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.969763</td>\n",
       "      <td>0.842502</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.813202</td>\n",
       "      <td>0.901777</td>\n",
       "      <td>0.706219</td>\n",
       "      <td>0.380906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.968187</td>\n",
       "      <td>0.983965</td>\n",
       "      <td>0.787255</td>\n",
       "      <td>0.190315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.826949</td>\n",
       "      <td>0.909367</td>\n",
       "      <td>0.713406</td>\n",
       "      <td>0.367307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.986194</td>\n",
       "      <td>0.993073</td>\n",
       "      <td>0.789912</td>\n",
       "      <td>0.249207</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.968701</td>\n",
       "      <td>0.984226</td>\n",
       "      <td>0.789719</td>\n",
       "      <td>0.189805</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>1.190927</td>\n",
       "      <td>1.091296</td>\n",
       "      <td>0.965662</td>\n",
       "      <td>-0.429112</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.986194</td>\n",
       "      <td>0.993073</td>\n",
       "      <td>0.789912</td>\n",
       "      <td>0.249207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.969318</td>\n",
       "      <td>0.984540</td>\n",
       "      <td>0.790220</td>\n",
       "      <td>0.189368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.984697</td>\n",
       "      <td>0.992319</td>\n",
       "      <td>0.789940</td>\n",
       "      <td>0.246615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.171221</td>\n",
       "      <td>1.082230</td>\n",
       "      <td>0.857404</td>\n",
       "      <td>0.108345</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.197711</td>\n",
       "      <td>1.094400</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>useravg</td>\n",
       "      <td>0.958643</td>\n",
       "      <td>0.979103</td>\n",
       "      <td>0.811926</td>\n",
       "      <td>-0.150372</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.171221</td>\n",
       "      <td>1.082230</td>\n",
       "      <td>0.857404</td>\n",
       "      <td>0.108345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.197084</td>\n",
       "      <td>1.094113</td>\n",
       "      <td>0.917136</td>\n",
       "      <td>-0.001110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.173515</td>\n",
       "      <td>1.083289</td>\n",
       "      <td>0.862702</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.344811</td>\n",
       "      <td>1.159660</td>\n",
       "      <td>0.957483</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.197711</td>\n",
       "      <td>1.094400</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.190927</td>\n",
       "      <td>1.091296</td>\n",
       "      <td>0.965662</td>\n",
       "      <td>-0.429112</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.161611</td>\n",
       "      <td>1.077781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161611</td>\n",
       "      <td>User-Item-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.344811</td>\n",
       "      <td>1.159660</td>\n",
       "      <td>0.957483</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.197686</td>\n",
       "      <td>1.094388</td>\n",
       "      <td>0.917534</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.331762</td>\n",
       "      <td>1.154020</td>\n",
       "      <td>0.953939</td>\n",
       "      <td>-0.018923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method       mse      rmse       mae  r2_score  \\\n",
       "1  itemknnpearson  0.968187  0.983965  0.787255  0.190315   \n",
       "0  itemknnpearson  0.817426  0.904116  0.707335  0.374592   \n",
       "0   itemknncosine  0.813202  0.901777  0.706219  0.380906   \n",
       "1   itemknncosine  0.968217  0.983980  0.787066  0.190210   \n",
       "2   itemknncosine  0.940441  0.969763  0.842502 -0.128529   \n",
       "3   itemknncosine  1.161611  1.077781  1.000000 -0.161611   \n",
       "0   itemknncosine  0.813202  0.901777  0.706219  0.380906   \n",
       "1   itemknncosine  0.968187  0.983965  0.787255  0.190315   \n",
       "0   itemknncosine  0.826949  0.909367  0.713406  0.367307   \n",
       "0         itemavg  0.986194  0.993073  0.789912  0.249207   \n",
       "1         itemavg  0.968701  0.984226  0.789719  0.189805   \n",
       "2         itemavg  1.190927  1.091296  0.965662 -0.429112   \n",
       "3         itemavg  1.161611  1.077781  1.000000 -0.161611   \n",
       "0         itemavg  0.986194  0.993073  0.789912  0.249207   \n",
       "1         itemavg  0.969318  0.984540  0.790220  0.189368   \n",
       "0         itemavg  0.984697  0.992319  0.789940  0.246615   \n",
       "0         useravg  1.171221  1.082230  0.857404  0.108345   \n",
       "1         useravg  1.197711  1.094400  0.917391 -0.001733   \n",
       "2         useravg  0.958643  0.979103  0.811926 -0.150372   \n",
       "3         useravg  1.161611  1.077781  1.000000 -0.161611   \n",
       "0         useravg  1.171221  1.082230  0.857404  0.108345   \n",
       "1         useravg  1.197084  1.094113  0.917136 -0.001110   \n",
       "0         useravg  1.173515  1.083289  0.862702  0.102151   \n",
       "0      global_avg  1.344811  1.159660  0.957483 -0.023810   \n",
       "1      global_avg  1.197711  1.094400  0.917391 -0.001733   \n",
       "2      global_avg  1.190927  1.091296  0.965662 -0.429112   \n",
       "3      global_avg  1.161611  1.077781  1.000000 -0.161611   \n",
       "0      global_avg  1.344811  1.159660  0.957483 -0.023810   \n",
       "1      global_avg  1.197686  1.094388  0.917534 -0.001614   \n",
       "0      global_avg  1.331762  1.154020  0.953939 -0.018923   \n",
       "\n",
       "       Cold Start Group  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  \n",
       "0         No-cold-start  \n",
       "1       User-Cold-Start  \n",
       "2       Item-Cold_start  \n",
       "3  User-Item-cold-start  \n",
       "0                     0  \n",
       "1                     1  \n",
       "0                     0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_concat[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.generate_scores=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.765174284478508, 0.6913009601924905, 0.8623963581479989)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.run_epoch(dlvalid,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9013758, 3.5500436, 3.4768884, ..., 3.3399463, 2.869813 ,\n",
       "       3.1324563], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(learner.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvalid['pred_cf']=np.concatenate(learner.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747827768768243"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(metrics.mean_squared_error(dfvalid['rating'],dfvalid['pred_cf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_by_group (dfvalid,predVar,groupVar='cold_start_group',method='global_avg'):\n",
    "    scores=[]\n",
    "    mae_scores=[]\n",
    "    rmse_scores=[]\n",
    "    r2_scores=[]\n",
    "    groups=dfvalid[groupVar].value_counts().index.tolist()\n",
    "    for group in groups:\n",
    "        df=dfvalid.loc[dfvalid[groupVar]==group]\n",
    "        actual=df['rating']\n",
    "        score=metrics.mean_squared_error(df['rating'],df[predVar])\n",
    "        rmse_score=np.sqrt(metrics.mean_squared_error(df['rating'],df[predVar]))\n",
    "        mae_score=metrics.mean_absolute_error(df['rating'],df[predVar])\n",
    "        r2_score=metrics.r2_score(df['rating'],df[predVar])\n",
    "        scores.append(score)\n",
    "        mae_scores.append(mae_score)\n",
    "        rmse_scores.append(rmse_score)\n",
    "        r2_scores.append(r2_score)\n",
    "    return pd.DataFrame({'method':method, 'mse':scores, 'rmse':rmse_scores, 'mae':mae_scores, 'r2_score':r2_scores, 'Cold Start Group':groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>Cold Start Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>0.691351</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.650572</td>\n",
       "      <td>0.806581</td>\n",
       "      <td>0.657555</td>\n",
       "      <td>0.066269</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.868267</td>\n",
       "      <td>0.931808</td>\n",
       "      <td>0.776163</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>0.691351</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.686632</td>\n",
       "      <td>0.828633</td>\n",
       "      <td>0.677201</td>\n",
       "      <td>0.116983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765245</td>\n",
       "      <td>0.874783</td>\n",
       "      <td>0.691330</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method       mse      rmse       mae  r2_score Cold Start Group\n",
       "0     cf  0.765366  0.874852  0.691351  0.417669    No-cold-start\n",
       "1     cf  0.650572  0.806581  0.657555  0.066269  User-Cold-Start\n",
       "2     cf  0.868267  0.931808  0.776163  0.060881  Item-Cold_start\n",
       "0     cf  0.765366  0.874852  0.691351  0.417669                0\n",
       "1     cf  0.686632  0.828633  0.677201  0.116983                1\n",
       "0     cf  0.765245  0.874783  0.691330  0.417400                0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cf=pd.concat([score_by_group(dfvalid,'pred_cf','cold_start_group','cf'),score_by_group(dfvalid,'pred_cf','cold_start_bucket','cf'),\\\n",
    "score_by_group(dfvalid,'pred_cf','flag_train','cf')],axis=0)\n",
    "result_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type cf. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kirana/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type cf. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cfobj,f=f'{DATAPATH}/inter/cf_model')\n",
    "torch.save(learner,f=f'{DATAPATH}/inter/cf_learner')\n",
    "torch.save(optimizer,f=f'{DATAPATH}/inter/cf_optimizer')\n",
    "torch.save(cfobj.state_dict(),f'{DATAPATH}/inter/cf_state_dict')\n",
    "torch.save(optimizer.state_dict(),f'{DATAPATH}/inter/cf_optimizer_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_user_emb=cfobj.emb_user.weight.data.cpu().numpy()\n",
    "mtx_item_emb=cfobj.emb_item.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bias_emb=cfobj.ub.weight.data.cpu().numpy()\n",
    "item_bias_emb=cfobj.ib.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6041, 25), (3707, 25), (6041, 1), (3707, 1))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_user_emb.shape, mtx_item_emb.shape, user_bias_emb.shape, item_bias_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([mtx_user_emb,mtx_item_emb,user_bias_emb,item_bias_emb],open(f'{DATAPATH}/wts_embs','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concat=pd.concat([results_concat,result_cf],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([df,dftrain,dfvalid,idx_to_user,idx_to_item,item_to_idx,user_to_idx,results_concat],open(f'{DATAPATH}/df_side_cold_runother_cf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>Cold Start Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.760925</td>\n",
       "      <td>0.872310</td>\n",
       "      <td>0.686220</td>\n",
       "      <td>0.421048</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.753373</td>\n",
       "      <td>0.867971</td>\n",
       "      <td>0.645315</td>\n",
       "      <td>-0.081275</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>1.037496</td>\n",
       "      <td>1.018575</td>\n",
       "      <td>0.870312</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.760925</td>\n",
       "      <td>0.872310</td>\n",
       "      <td>0.686220</td>\n",
       "      <td>0.421048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.800436</td>\n",
       "      <td>0.894671</td>\n",
       "      <td>0.682585</td>\n",
       "      <td>-0.029370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biasedmatrixfactorization</td>\n",
       "      <td>0.760985</td>\n",
       "      <td>0.872345</td>\n",
       "      <td>0.686215</td>\n",
       "      <td>0.420643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.759324</td>\n",
       "      <td>0.871392</td>\n",
       "      <td>0.680946</td>\n",
       "      <td>0.422266</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.698857</td>\n",
       "      <td>0.835976</td>\n",
       "      <td>0.626766</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>1.103733</td>\n",
       "      <td>1.050587</td>\n",
       "      <td>0.904871</td>\n",
       "      <td>-0.193801</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.759324</td>\n",
       "      <td>0.871392</td>\n",
       "      <td>0.680946</td>\n",
       "      <td>0.422266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.765922</td>\n",
       "      <td>0.875170</td>\n",
       "      <td>0.672832</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svdplusplus</td>\n",
       "      <td>0.759334</td>\n",
       "      <td>0.871398</td>\n",
       "      <td>0.680933</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.766443</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.687194</td>\n",
       "      <td>0.416850</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.696767</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.692595</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>1.241766</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>0.992714</td>\n",
       "      <td>-0.343097</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.766443</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.687194</td>\n",
       "      <td>0.416850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.887154</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.766474</td>\n",
       "      <td>0.875485</td>\n",
       "      <td>0.687279</td>\n",
       "      <td>0.416464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.838119</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.717952</td>\n",
       "      <td>0.362315</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.751093</td>\n",
       "      <td>0.866656</td>\n",
       "      <td>0.642135</td>\n",
       "      <td>-0.078002</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.978135</td>\n",
       "      <td>0.989007</td>\n",
       "      <td>0.835461</td>\n",
       "      <td>-0.057953</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.838119</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.717952</td>\n",
       "      <td>0.362315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>0.888088</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknncosine</td>\n",
       "      <td>0.838043</td>\n",
       "      <td>0.915447</td>\n",
       "      <td>0.717885</td>\n",
       "      <td>0.361977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.823815</td>\n",
       "      <td>0.907643</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.373198</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.751093</td>\n",
       "      <td>0.866656</td>\n",
       "      <td>0.642135</td>\n",
       "      <td>-0.078002</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.978135</td>\n",
       "      <td>0.989007</td>\n",
       "      <td>0.835461</td>\n",
       "      <td>-0.057953</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.823815</td>\n",
       "      <td>0.907643</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.373198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>0.888088</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userknnpearson</td>\n",
       "      <td>0.823761</td>\n",
       "      <td>0.907613</td>\n",
       "      <td>0.711990</td>\n",
       "      <td>0.372850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.813232</td>\n",
       "      <td>0.901794</td>\n",
       "      <td>0.706641</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.751093</td>\n",
       "      <td>0.866656</td>\n",
       "      <td>0.642135</td>\n",
       "      <td>-0.078002</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.978135</td>\n",
       "      <td>0.989007</td>\n",
       "      <td>0.835461</td>\n",
       "      <td>-0.057953</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.813232</td>\n",
       "      <td>0.901794</td>\n",
       "      <td>0.706641</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.788701</td>\n",
       "      <td>0.888088</td>\n",
       "      <td>0.674158</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemknncosine</td>\n",
       "      <td>0.813194</td>\n",
       "      <td>0.901773</td>\n",
       "      <td>0.706591</td>\n",
       "      <td>0.380895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>0.992205</td>\n",
       "      <td>0.789484</td>\n",
       "      <td>0.250963</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.709953</td>\n",
       "      <td>0.842587</td>\n",
       "      <td>0.627969</td>\n",
       "      <td>-0.018957</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>1.241766</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>0.992714</td>\n",
       "      <td>-0.343097</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.984470</td>\n",
       "      <td>0.992205</td>\n",
       "      <td>0.789484</td>\n",
       "      <td>0.250963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.798045</td>\n",
       "      <td>0.893334</td>\n",
       "      <td>0.688387</td>\n",
       "      <td>-0.026295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itemavg</td>\n",
       "      <td>0.984184</td>\n",
       "      <td>0.992060</td>\n",
       "      <td>0.789329</td>\n",
       "      <td>0.250716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.174381</td>\n",
       "      <td>1.083689</td>\n",
       "      <td>0.858543</td>\n",
       "      <td>0.106469</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useravg</td>\n",
       "      <td>0.696767</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.692595</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>useravg</td>\n",
       "      <td>0.987253</td>\n",
       "      <td>0.993606</td>\n",
       "      <td>0.808567</td>\n",
       "      <td>-0.067816</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.174381</td>\n",
       "      <td>1.083689</td>\n",
       "      <td>0.858543</td>\n",
       "      <td>0.106469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useravg</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.711805</td>\n",
       "      <td>0.042070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>useravg</td>\n",
       "      <td>1.173721</td>\n",
       "      <td>1.083384</td>\n",
       "      <td>0.858317</td>\n",
       "      <td>0.106417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.345409</td>\n",
       "      <td>1.159918</td>\n",
       "      <td>0.957762</td>\n",
       "      <td>-0.023659</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>0.696767</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.692595</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.241766</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>0.992714</td>\n",
       "      <td>-0.343097</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.345409</td>\n",
       "      <td>1.159918</td>\n",
       "      <td>0.957762</td>\n",
       "      <td>-0.023659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.887154</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_avg</td>\n",
       "      <td>1.344551</td>\n",
       "      <td>1.159548</td>\n",
       "      <td>0.957431</td>\n",
       "      <td>-0.023641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>0.691351</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>No-cold-start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.650572</td>\n",
       "      <td>0.806581</td>\n",
       "      <td>0.657555</td>\n",
       "      <td>0.066269</td>\n",
       "      <td>User-Cold-Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.868267</td>\n",
       "      <td>0.931808</td>\n",
       "      <td>0.776163</td>\n",
       "      <td>0.060881</td>\n",
       "      <td>Item-Cold_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>0.691351</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.686632</td>\n",
       "      <td>0.828633</td>\n",
       "      <td>0.677201</td>\n",
       "      <td>0.116983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cf</td>\n",
       "      <td>0.765245</td>\n",
       "      <td>0.874783</td>\n",
       "      <td>0.691330</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method       mse      rmse       mae  r2_score  \\\n",
       "0   biasedmatrixfactorization  0.760925  0.872310  0.686220  0.421048   \n",
       "1   biasedmatrixfactorization  0.753373  0.867971  0.645315 -0.081275   \n",
       "2   biasedmatrixfactorization  1.037496  1.018575  0.870312 -0.122158   \n",
       "0   biasedmatrixfactorization  0.760925  0.872310  0.686220  0.421048   \n",
       "1   biasedmatrixfactorization  0.800436  0.894671  0.682585 -0.029370   \n",
       "0   biasedmatrixfactorization  0.760985  0.872345  0.686215  0.420643   \n",
       "0                 svdplusplus  0.759324  0.871392  0.680946  0.422266   \n",
       "1                 svdplusplus  0.698857  0.835976  0.626766 -0.003030   \n",
       "2                 svdplusplus  1.103733  1.050587  0.904871 -0.193801   \n",
       "0                 svdplusplus  0.759324  0.871392  0.680946  0.422266   \n",
       "1                 svdplusplus  0.765922  0.875170  0.672832  0.015015   \n",
       "0                 svdplusplus  0.759334  0.871398  0.680933  0.421900   \n",
       "0                         svd  0.766443  0.875467  0.687194  0.416850   \n",
       "1                         svd  0.696767  0.834726  0.692595 -0.000031   \n",
       "2                         svd  1.241766  1.114346  0.992714 -0.343097   \n",
       "0                         svd  0.766443  0.875467  0.687194  0.416850   \n",
       "1                         svd  0.787043  0.887154  0.742308 -0.012146   \n",
       "0                         svd  0.766474  0.875485  0.687279  0.416464   \n",
       "0               userknncosine  0.838119  0.915488  0.717952  0.362315   \n",
       "1               userknncosine  0.751093  0.866656  0.642135 -0.078002   \n",
       "2               userknncosine  0.978135  0.989007  0.835461 -0.057953   \n",
       "0               userknncosine  0.838119  0.915488  0.717952  0.362315   \n",
       "1               userknncosine  0.788701  0.888088  0.674158 -0.014279   \n",
       "0               userknncosine  0.838043  0.915447  0.717885  0.361977   \n",
       "0              userknnpearson  0.823815  0.907643  0.712049  0.373198   \n",
       "1              userknnpearson  0.751093  0.866656  0.642135 -0.078002   \n",
       "2              userknnpearson  0.978135  0.989007  0.835461 -0.057953   \n",
       "0              userknnpearson  0.823815  0.907643  0.712049  0.373198   \n",
       "1              userknnpearson  0.788701  0.888088  0.674158 -0.014279   \n",
       "0              userknnpearson  0.823761  0.907613  0.711990  0.372850   \n",
       "..                        ...       ...       ...       ...       ...   \n",
       "0               itemknncosine  0.813232  0.901794  0.706641  0.381250   \n",
       "1               itemknncosine  0.751093  0.866656  0.642135 -0.078002   \n",
       "2               itemknncosine  0.978135  0.989007  0.835461 -0.057953   \n",
       "0               itemknncosine  0.813232  0.901794  0.706641  0.381250   \n",
       "1               itemknncosine  0.788701  0.888088  0.674158 -0.014279   \n",
       "0               itemknncosine  0.813194  0.901773  0.706591  0.380895   \n",
       "0                     itemavg  0.984470  0.992205  0.789484  0.250963   \n",
       "1                     itemavg  0.709953  0.842587  0.627969 -0.018957   \n",
       "2                     itemavg  1.241766  1.114346  0.992714 -0.343097   \n",
       "0                     itemavg  0.984470  0.992205  0.789484  0.250963   \n",
       "1                     itemavg  0.798045  0.893334  0.688387 -0.026295   \n",
       "0                     itemavg  0.984184  0.992060  0.789329  0.250716   \n",
       "0                     useravg  1.174381  1.083689  0.858543  0.106469   \n",
       "1                     useravg  0.696767  0.834726  0.692595 -0.000031   \n",
       "2                     useravg  0.987253  0.993606  0.808567 -0.067816   \n",
       "0                     useravg  1.174381  1.083689  0.858543  0.106469   \n",
       "1                     useravg  0.744884  0.863067  0.711805  0.042070   \n",
       "0                     useravg  1.173721  1.083384  0.858317  0.106417   \n",
       "0                  global_avg  1.345409  1.159918  0.957762 -0.023659   \n",
       "1                  global_avg  0.696767  0.834726  0.692595 -0.000031   \n",
       "2                  global_avg  1.241766  1.114346  0.992714 -0.343097   \n",
       "0                  global_avg  1.345409  1.159918  0.957762 -0.023659   \n",
       "1                  global_avg  0.787043  0.887154  0.742308 -0.012146   \n",
       "0                  global_avg  1.344551  1.159548  0.957431 -0.023641   \n",
       "0                          cf  0.765366  0.874852  0.691351  0.417669   \n",
       "1                          cf  0.650572  0.806581  0.657555  0.066269   \n",
       "2                          cf  0.868267  0.931808  0.776163  0.060881   \n",
       "0                          cf  0.765366  0.874852  0.691351  0.417669   \n",
       "1                          cf  0.686632  0.828633  0.677201  0.116983   \n",
       "0                          cf  0.765245  0.874783  0.691330  0.417400   \n",
       "\n",
       "   Cold Start Group  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "..              ...  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "0     No-cold-start  \n",
       "1   User-Cold-Start  \n",
       "2   Item-Cold_start  \n",
       "0                 0  \n",
       "1                 1  \n",
       "0                 0  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
